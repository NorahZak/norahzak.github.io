<!DOCTYPE html>
<html>
<meta  lang="en" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <link rel="icon" href="/img/Kaze.png">
  <title>theme-kaze demo</title>
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_vpj3dq9ceqa.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_vpj3dq9ceqa.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
<meta name="generator" content="Hexo 5.4.1"></head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/img/Kaze.png">
      
      <span class="navbar-logo-dsc">theme-kaze demo</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">Home </a>
    
    <a href="/archives" class="navbar-menu-item">Archive </a>
    
    <a href="/tags" class="navbar-menu-item">Tags </a>
    
    <a href="/categories" class="navbar-menu-item">Categories </a>
    
    <a href="/about" class="navbar-menu-item">About </a>
    
    <a href="/links" class="navbar-menu-item">Friends </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
  </div>
</nav>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2020-04-10T01:21:14.000Z" style="display: flex; align-items: center;">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2020-04-10</span>
    </time>
    
    
    <span class="dot"></span>
    <span>1.4k words</span>
    
  </div>
  
  </header>
  <div id="section" class="post-content">
    <h1 id="Paper-draft"><a href="#Paper-draft" class="headerlink" title="Paper draft"></a>Paper draft</h1><p>[TOC]</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this paper we proposes a new method for face image motion deblurring .</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Single image motion deblurring is a widely explored area and has many applications in real world. Motion blur in images are caused by the relative motion between the scene and the camera during exposure time . Since many photos in real world are captured by amateur people with hand-held devices such as cameras and mobile phones, the photos often suffers from the motion blur caused by hand shake . The motion blurred images are not only visually unpleasant , but can also affect the result of automatic image recognition (e.g. image classification , object detection , face recognition , etc.).  </p>
<p>To remove the motion blur from image , many researchers have proposed their methods . Traditional methods estimate the motion blur kernel , and recover the latent sharp image by deconvolution. Recently, deep learning and convolutional neural network are showing promising potential at many computer vision tasks. including those image-to-image tasks such as image recovery, style transfer and impainting. To exploit the potential of CNN in image motion deblurring , some researchers have collected and generated large datasets with many synthesized motion blurred images and corresponding sharp images . Based on the data , many CNN-based motion deblurring methods are proposed , and get promising results .</p>
<p>While motion deblurring method for general images is already well researched, little efforts have been put into motion deblurring for domain-specific images. In contrast to general images , domain-specific images have many special characteristics . For example , face images are highly structural and have fixed components (eyes , eyebrow , nose , mouth , hair , ear and background ). By exploiting these special proporties, we can take a further step on domain-specific image motion deblurring than general methods .</p>
<h2 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h2><h3 id="Single-image-motion-deblurring"><a href="#Single-image-motion-deblurring" class="headerlink" title="Single image motion deblurring"></a>Single image motion deblurring</h3><p>Single image motion deblurring is a well-researched problem that has many applications in real world. Traditional methods tried to estimate the blur kernel, and use deconvolution to estimate the latent sharp image from its motion blurred counterpart. Since it’s a highly ill-posed problem (i.e. given observed blur image B, there are infinite pairs of sharp image S and blur kernel K that can lead to B by convolution),  these methods used hand-crafted image priors to regularize the optimization process, such as total variation [1], hyper-Laplacian prior [2], sparse image prior [3], heavy-tailed gradient prior [4, 13], l0-norm gradient prior [5], dark channel prior [14], extreme channel prior [15] and local maximum gradient prior [16]. However, methods in this category are very time-comsuming because  they have to estimate the sharp image and blur kernel in an iterative way to make the estimation more accurate. And to simplify the problem, they made some assumptions on the blur pattern such as uniform blur and linear blur , which are often violated in real world. What’s more , the image priors often have limitation in some circumstances , such as low light and text image .</p>
<p>Due to these holdbacks and the recent success of deep learning in image processing, many CNN-based methods have appeared in this area. In contrast to traditional methods , they made no assumptions about the blur pattern , and do not need any hand-crafted image priors. Instead they let the model learn these features automatically from data in an end-to-end way. Nah [17] proposed to use a multi-scale encoder-decoder CNN to recover the sharp image from its motion blurred counterpart in an end-to-end way . Tao [18] introduced ConvLSTM to encoder-decoder structure for passing information between adjacent scale . Kupyn [19] uses GAN to make the recovered image more realistic . </p>
<p>CNN-based methods requires large datasets consist of pairs of motion blurred images and corresponding sharp images for training . Nah [17] uses a high speed  camera to capture videos , and synthesizes motion blur images by averaging several consecutive frames . Brooks [6] proposed to use CNN for generating high quality motion blurred image using 2 consecutive frame from arbitrary videos . G. Boracchi [22] generate motion blurred images by mimic camera 3D motion trajectory .</p>
<h3 id="Face-image-motion-deblurring"><a href="#Face-image-motion-deblurring" class="headerlink" title="Face image motion deblurring"></a>Face image motion deblurring</h3><p>Pan [23] proposed to deblur face images using exemplars . Shen [20] proposed to deblur face images using semantic information from external data as image prior . They used a multi-scale encoder-decoder network for deblurring. For exploiting the semantic information of face images , they concatenated the facial parsing mask with blurred face image as input, and used local structural loss to train the network . The parsing mask serves as a global prior for deblurring, and the local structural loss (the sum of $L_1$ loss of each face component) help the network better recover the face components (eyes, noses, etc.) since they are relatively smaller but more important than other parts of face image (background, hair, skin, etc.). Yasarla [21] also exploits the semantic information for face deblurring. It first uses different branches (Multi-Stream Network) to deblur different semantic parts in face image (i.e. hair, skin, background, facial features), then combines these results to get the final result. And they designed a Confidence Network to predict the confidence of the deblurring result for each class , and uses them as the loss weight for each class in training phase .</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] T.F.Chan and C.K.Wong. Total variation blind deconvolution. <em>IEEE Trans. on Image Processing</em>, 7(3):370–375, 1998.</p>
<p>[2] D. Krishnan and R. Fergus. Fast image deconvolution using hyper-laplacian priors. In <em>NIPS</em>, pages 1033–1041, 2009.</p>
<p>[3] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman. Understanding and evaluating blind deconvolution algorithms. In <em>CVPR</em>, pages 1964–1971. IEEE, 2009.</p>
<p>[4] Q. Shan, J. Jia, and A. Agarwala. High-quality motion deblurring from a single image. volume 27, page 73. ACM, 2008.</p>
<p>[5] L. Xu, S. Zheng, and J. Jia. Unnatural l0 sparse representation for natural image deblurring. In <em>CVPR</em>, pages 1107– 1114. IEEE, 2013.</p>
<p>[6] Brooks, Tim, and Jonathan T. Barron. “Learning to Synthesize Motion Blur.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2019.</p>
<p>[7] J. Sun, W. Cao, Z. Xu, and J. Ponce. Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal. 2015. 3, 5, 7, 8</p>
<p>[8] L. Xu, J. S. J. Ren, C. Liu, and J. Jia. Deep convolutional neural network for image deconvolution. In Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 1, NIPS’14, pages 1790–1798, Cambridge, MA, USA, 2014. MIT Press. 5</p>
<p>[9] A. Chakrabarti. A neural approach to blind motion deblurring. In Lecture Notes in Computer Science (including sub-series Lecture Notes in Artificial Intelligence and LectureNotes in Bioinformatics), 2016. 3, 5</p>
<p>[10] Kupyn, Orest, et al. “Deblurgan: Blind motion deblurring using conditional adversarial networks.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2018.</p>
<p>[11] Nah, Seungjun, Tae Hyun Kim, and Kyoung Mu Lee. “Deep multi-scale convolutional neural network for dynamic scene deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2017.</p>
<p>[12] Schmidt, Uwe, et al. “Discriminative non-blind deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2013.</p>
<p>[13] Robert Fergus, Barun Singh, Aaron Hertzmann, Sam T. Roweis, and William T. Freeman. Removing camera shake from a single photograph. ACM Transactions on Graphics, 25(3):787–794, 2006.</p>
<p>[14] Jinshan Pan, Deqing Sun, Hanspeter Pfister, and MingHsuan Yang. Blind image deblurring using dark channel prior. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.</p>
<p>[15]  Yan, Yanyang, et al. “Image deblurring via extreme channels prior.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2017.</p>
<p>[16]  Chen, Liang, et al. “Blind Image Deblurring With Local Maximum Gradient Prior.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2019.</p>
<p>[17]  S. Nah, T. H. Kim, and K. M. Lee. Deep multi-scale convolutional neural network for dynamic scene deblurring. pages 3883–3891, 2017.</p>
<p>[18]  Tao, Xin, et al. “Scale-recurrent network for deep image deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2018.</p>
<p>[19]  Kupyn, Orest, et al. “Deblurgan: Blind motion deblurring using conditional adversarial networks.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2018.</p>
<p>[20] Shen, Ziyi, et al. “Deep semantic face deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2018.</p>
<p>[21] Yasarla, Rajeev, Federico Perazzi, and Vishal M. Patel. “Deblurring Face Images using Uncertainty Guided Multi-Stream Semantic Networks.” arXiv preprint arXiv:1907.13106 (2019).</p>
<p>[22] G. Boracchi and A. Foi. Modeling the performance of image restoration from motion blur. TIP, 21(8):3502–3517, 2012.</p>
<p>[23] Pan, Jinshan, et al. “Deblurring face images with exemplars.” <em>European conference on computer vision</em>. Springer, Cham, 2014.</p>

  </div>
  <div>
  
  <div class="post-note note-warning copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://example.com/about">theme-kaze</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://example.com/2020/04/10/Paper%20draft/">http://example.com/2020/04/10/Paper%20draft/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/2020/04/10/One-stage object detection method for severely downgraded images/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">Prev</div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/2020/04/10/README/" class="nav-link">
      <div>
        <div class="nav-label">Next</div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Paper-draft"><span class="toc-text">Paper draft</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-works"><span class="toc-text">Related works</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Single-image-motion-deblurring"><span class="toc-text">Single image motion deblurring</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Face-image-motion-deblurring"><span class="toc-text">Face image motion deblurring</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-text">References</span></a></li></ol></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/img/Kaze.png" class="author-img">

<p class="author-name">theme-kaze</p>
<p class="author-description">designed by theme-kaze</p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>30</span>
    <span>Posts</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>0</span>
    <span>Categories</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>0</span>
    <span>Tags</span>
  </a>
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Paper-draft"><span class="toc-text">Paper draft</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-works"><span class="toc-text">Related works</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Single-image-motion-deblurring"><span class="toc-text">Single image motion deblurring</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Face-image-motion-deblurring"><span class="toc-text">Face image motion deblurring</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-text">References</span></a></li></ol></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>Categories</div>
  <div class="categories-list">
    
  </div>
</div>
  </article>
  
  <article class="card card-content">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>hot tags</div>
  <div class="tags-list">
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">
  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Paper-draft"><span class="toc-text">Paper draft</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-works"><span class="toc-text">Related works</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Single-image-motion-deblurring"><span class="toc-text">Single image motion deblurring</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Face-image-motion-deblurring"><span class="toc-text">Face image motion deblurring</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-text">References</span></a></li></ol></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>Recent Posts</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-09-12</div>
        <a href="/2020/09/12/Python 闭包的作用/"><div class="recent-posts-item-content"></div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-09-12</div>
        <a href="/2020/09/12/C++ const关键字的用法/"><div class="recent-posts-item-content"></div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-08-28</div>
        <a href="/2020/08/28/面试常见问题/"><div class="recent-posts-item-content"></div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-08-07</div>
        <a href="/2020/08/07/集成学习/"><div class="recent-posts-item-content"></div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2022
        </span>
        <a href="/" class="footer-link">theme-kaze demo </a>
      </div>
    </div>

    
    <div class="footer-dsc">
      
      
      Powered by
      <a href="https://hexo.io/" class="footer-link" target="_blank" rel="nofollow noopener noreferrer">&nbsp;Hexo </a>
      
      
      <span>&nbsp;|&nbsp;</span>
      
      
      
      Theme -
      <a href="https://github.com/theme-kaze" class="footer-link" target="_blank"
        rel="nofollow noopener noreferrer">&nbsp;Kaze</a>
      
    </div>
    
    
    
    
</footer>
  <a role="button" id="scrollbutton" class="basebutton" >
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget">
  <i class="iconfont icon-weather button-icon"></i>
</a>

  
  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.setAttribute('style', 'width: 100%; display: flex; justify-content: center;');
      img[i].parentElement.insertBefore(wrapper, img[i]);
      wrapper.appendChild(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
</body>

</html>