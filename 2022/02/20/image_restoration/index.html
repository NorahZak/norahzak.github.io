<!DOCTYPE html>
<html>
<meta  lang="en" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <link rel="icon" href="/img/Kaze.png">
  <title>theme-kaze demo</title>
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_vpj3dq9ceqa.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_vpj3dq9ceqa.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
<meta name="generator" content="Hexo 5.4.1"></head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/img/Kaze.png">
      
      <span class="navbar-logo-dsc">theme-kaze demo</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">Home </a>
    
    <a href="/archives" class="navbar-menu-item">Archive </a>
    
    <a href="/tags" class="navbar-menu-item">Tags </a>
    
    <a href="/categories" class="navbar-menu-item">Categories </a>
    
    <a href="/about" class="navbar-menu-item">About </a>
    
    <a href="/links" class="navbar-menu-item">Friends </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
  </div>
</nav>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      图像复原算法综述
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2022-02-20T03:36:59.000Z" style="display: flex; align-items: center;">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2022-02-20</span>
    </time>
    
    
    <span class="dot"></span>
    <span>2.6k words</span>
    
  </div>
  
  <div class="post-meta post-show-meta" style="margin-top: -10px;">
    <div style="display: flex; align-items: center;">
      <i class="iconfont icon-biaoqian" style="margin-right: 2px; font-size: 1.15rem;"></i>
      
      
        <a href="/tags/Computer-vision/" class="post-meta-link">Computer vision</a>
      
    </div>
  </div>
  
  </header>
  <div id="section" class="post-content">
    <h1 id="图像复原"><a href="#图像复原" class="headerlink" title="图像复原"></a>图像复原</h1><p>[TOC]</p>
<h2 id="Motion-deblur"><a href="#Motion-deblur" class="headerlink" title="Motion deblur"></a>Motion deblur</h2><p><strong><code>数据集与评价指标</code></strong></p>
<p>(1) Anat Levin, Yair Weiss, Fredo Durand, and William T Freeman. Understanding and evaluating blind deconvolution algorithms. In IEEE Conference on Computer Vision and Pattern Recognition, 2009.</p>
<p><em><strong>This dataset consists of 32 synthesized motion blurred images. They are generated from 4 sharp images using 8 different blur kernels.</strong></em> </p>
<p><em><strong>Due to the relative translation between ground truth and deconvolution result, calculating PSNR directly will cause inaccuracy of the result. Thus, we use error ratio as performance evaluation on this dataset instead.</strong></em></p>
<p>(2) Wei-Sheng Lai, Jia-Bin Huang, Zhe Hu, Narendra Ahuja, and Ming-Hsuan Yang. A comparative study for single image blind deblurring. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.</p>
<p>(3) Rolf Kohler, Michael Hirsch, Betty Mohler, Bernhard ¨ Scholkopf, and Stefan Harmeling. Recording and playback ¨ of camera shake: Benchmarking blind deconvolution with a real-world database. In European Conference on Computer Vision, 2012.</p>
<p><em><strong>This dataset consists of 48 synthesized motion blurred images. They are generated from 4 sharp images using 12 different blur kernels.</strong></em></p>
<p><em><strong>This dataset uses PSNR as evaluation metric directly.</strong></em></p>
<p><strong><code>现有方法</code></strong></p>
<h3 id="Blind-single-image-deblurring-Optimization-based"><a href="#Blind-single-image-deblurring-Optimization-based" class="headerlink" title="Blind single image deblurring (Optimization-based)"></a>Blind single image deblurring (Optimization-based)</h3><p><em><strong>Common priors</strong></em></p>
<p>$||\nabla I||_0$: $L_0$-regularization term, used to force sparsity on latent sharp image. It works well on natural images (thus is used in most generic deblurring methods), but less effective on text images due to the characteristic of text.</p>
<p>$||\mathbf k||^2$: blur kernel regularization term, used to force smoothness on blur kernel, used by most deblurring methods.</p>
<p><strong><code>Removing camera shake from a single photograph</code></strong></p>
<p>Robert Fergus, Barun Singh, Aaron Hertzmann, Sam T. Roweis, and William T. Freeman. Removing camera shake from a single photograph. ACM Transactions on Graphics, 25(3):787–794, 2006.</p>
<p><strong>Prior on latent image I</strong></p>
<p>This paper suggested that the HOG(histogram of gradients) of natural images are of heavy-tailed distribution.</p>
<p><em><strong>Heavy-tailed distribution</strong></em></p>
<p>It’s a distribution that has thicker tail than exponential distribution. Specifically, if random variable $x\sim F(x)$, then $F(x)$ is a heavy-tailed distribution when:</p>
<p>$lim_{x\rightarrow \infty}e^{\lambda x}(1-F(x))=\infty$</p>
<p><strong>Prior on blur kernel k</strong></p>
<p>This paper suggested that blur kernel should be sparse.</p>
<p><strong><code>Efficient marginal likelihood optimization in blind deconvolution</code></strong></p>
<p>Anat Levin, Yair Weiss, Fredo Durand, and William T Freeman. Efficient marginal likelihood optimization in blind deconvolution. In IEEE Conference on Computer Vision and Pattern Recognition, 2011.</p>
<p>This paper derived an effective method to optimize the popular maximum a posteriori (MAP) framework.</p>
<p><strong><code>Blind deconvolution using a normalized sparsity measure</code></strong></p>
<p>Dilip Krishnan, Terence Tay, and Rob Fergus. Blind deconvolution using a normalized sparsity measure. In IEEE Conference on Computer Vision and Pattern Recognition, 2011.</p>
<p>This paper utilized an $L1/L2$ regularization which inherently favors clear image over blurred ones.</p>
<p><strong><code>Blind image deblurring using dark channel prior</code></strong></p>
<p>Jinshan Pan, Deqing Sun, Hanspeter Pfister, and MingHsuan Yang. Blind image deblurring using dark channel prior. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.</p>
<p><strong>Abstract</strong></p>
<p>This paper proposed to use dark channel prior for blind image deblurring. This is based on the observation that most pixels in natural images tend to have zero dark channel, while blurred images are not.</p>
<p><strong>Method</strong></p>
<p><em><strong>Notations</strong></em></p>
<p>$c$: color channel of image, $c \in &lt;!–swig￼0–&gt;$</p>
<p>$x$: coordinates of a pixel in image, $x=(row, col)$</p>
<p>$P(x)$: a local patch centered at $x$</p>
<p><em><strong>Dark channel prior</strong></em></p>
<p> $D(I)(x)=min_{c\in&lt;!–swig￼1–&gt;}(min_{y\in P(x)}I^c(y))$</p>
<p><em><strong>Properties</strong></em></p>
<p>$0&lt;=D(I)(x)&lt;=1$</p>
<p>$D(B)(x)&gt;=D(I)(x)$, for all x</p>
<p><em><strong>Regularization term based on DCP</strong></em></p>
<p>Since blurring process tend to increase the value of dark channel, our goal is to make the dark channel of latent image to get smaller (close to 0). Thus this paper uses $||D(I)||_0$ <em><strong>(why $L_0$ norm?)</strong></em> as regularization term.</p>
<p><em><strong>Final energy function</strong></em></p>
<p>$\mathop{min} \limits_{I,\mathbf k} ||B-I\bigotimes \mathbf k||^2+\beta ||D(I)||_0+\gamma ||\nabla I||_0+\tau ||\mathbf k||^2$</p>
<p>$||B-I\bigotimes \mathbf k||^2$: fidelity term, ensure the similarity between observed blur image B and the deconvolution result;</p>
<p>$||D(I)||_0$: dark channel prior mentioned above;</p>
<p>$||\nabla I||_0$: the $L_0$ norm of gradient, can be seen as # of non-zero gradients, used for ensuring that only the salient edges are retained, and the tiny edges are removed. It’s based on the assumption that natural image should have sparse gradient;</p>
<p>$||\mathbf k||^2$: used to ensure the blur kernel is smooth.</p>
<p><em><strong>Algorithm</strong></em></p>
<p>Iteratively optimize $I$ and $\mathbf k$ <em><strong>(why?)</strong></em> by solving these 2 problems:</p>
<p>$\begin{cases} \mathop{min} \limits_{I} ||B-I\bigotimes \mathbf k||^2+\beta ||D(I)||_0+\gamma ||\nabla I||<em>0,\\mathop{min} \limits</em>{\mathbf k} ||B-I\bigotimes \mathbf k||^2+\tau ||\mathbf k||^2.\end{cases}$</p>
<p><strong><code>Image deblurring via extreme channels prior</code></strong></p>
<p>Yan, Yanyang, et al. “Image deblurring via extreme channels prior.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2017.</p>
<p><strong>Abstract</strong></p>
<p>This paper introduced bright channel prior (which is the brightest pixel in local patch) based on observation that blurring process will reduce the value of bright channel of an image, and combined it with dark channel prior to form the extreme channels prior, and use its $L_0$ norm to regularize the deblurring process. </p>
<p><strong>Method</strong></p>
<p><em><strong>Notations</strong></em></p>
<p>$c$: color channel of image, $c \in &lt;!–swig￼2–&gt;$</p>
<p>$x$: coordinates of a pixel in image, $x=(row, col)$</p>
<p>$P(x)$: a local patch centered at $x$</p>
<p><em><strong>Bright channel prior</strong></em></p>
<p> $BCP(I)(x)=max_{c\in&lt;!–swig￼3–&gt;}(max_{y\in P(x)}I^c(y))$</p>
<p><em><strong>Properties</strong></em></p>
<p>$0&lt;=BCP(I)(x)&lt;=1$</p>
<p>$BCP(B)(x)&lt;=BCP(I)(x)$, for all x</p>
<p><em><strong>Regularization term based on BCP</strong></em></p>
<p>Since blurring process tend to reduce the value of bright channel, our goal is to make the bright channel of latent image to get larger (close to 1). Thus this paper uses $||1-BCP(I)||_0$ as regularization term.</p>
<p><em><strong>Final energy function</strong></em></p>
<p>$\mathop{min} \limits_{I,\mathbf k} ||B-I\bigotimes \mathbf k||^2+\beta ||DCP(I)||_0+\gamma ||1-BCP(I)||_0+\mu ||\nabla I||_0+\tau ||\mathbf k||^2$</p>
<p>$||B-I\bigotimes \mathbf k||^2$: fidelity term, ensure the similarity between observed blur image B and the deconvolution result;</p>
<p>$||DCP(I)||_0$: dark channel prior mentioned above;</p>
<p>$||BCP(I)||_0$: bright channel prior mentioned above;</p>
<p>$||\nabla I||_0$: the $L_0$ norm of gradient, can be seen as # of non-zero gradients, used for ensuring that only the salient edges are retained, and the tiny edges are removed. It’s based on the assumption that natural image should have sparse gradient;</p>
<p>$||\mathbf k||^2$: used to ensure the blur kernel is smooth.</p>
<p><em><strong>Algorithm</strong></em></p>
<p>Iteratively optimize $I$ and $\mathbf k$ <em><strong>(why?)</strong></em> by solving these 2 problems:</p>
<p>$\begin{cases} \mathop{min} \limits_{I} ||B-I\bigotimes \mathbf k||^2+\beta ||DCP(I)||_0+\gamma ||1-BCP(I)||_0+\mu ||\nabla I||<em>0,&amp;(1)\\mathop{min} \limits</em>{\mathbf k} ||B-I\bigotimes \mathbf k||^2+\tau ||\mathbf k||^2.&amp;(2)\end{cases}$</p>
<p>Considering that the $L_0$ regularization term is computationally intractable, we propose an efficient algorithm to solve in Eq. (1) based on the half-quadratic splitting technique.</p>
<p><strong><code>Phase-only Image Based Kernel Estimation for Single Image Blind Deblurring</code></strong></p>
<p>Pan, Liyuan, et al. “Phase-Only Image Based Kernel Estimation for Single Image Blind Deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2019.</p>
<p><strong>Abstract</strong></p>
<p>This paper uses phase-only image of an motion blurred image to estimate the blur kernel, then estimate the latent sharp image by solving an optimization problem.</p>
<p><strong>Method</strong></p>
<p><em><strong>Notations</strong></em></p>
<p>Blur image: $B$, latent sharp image: $L$, blur kernel: $\mathbf{k}$,</p>
<p>Fourier transform: $F(\centerdot)$, inverse fourier transform: $F^{-1}(\centerdot)$,</p>
<p>Complex: $z=ke^{i\theta}$, phase of complex: $e^{i\theta}$, amplitude of complex: $k$, </p>
<p>Extract phase-only image: $P(I)=F^{-1}(Phase(F(I)))$,</p>
<p>Rotation: $R(\centerdot)$, shift:$S(\centerdot)$</p>
<p>Self-correlation: $A(I)= \overline I\bigotimes I = F^{-1}(F(I)\bigodot \overline {F(I)})$</p>
<p><em><strong>Dirac delta function</strong></em>: $\delta(x)=\begin{cases}\infty&amp;x=0\0&amp;else\end{cases}$</p>
<p><em><strong>Kronecker delta function:</strong></em> $\delta(x)=\begin{cases}1&amp;x=0\0&amp;else\end{cases}$</p>
<p><em><strong>(The function used in paper is Dirac, but I doubt it might be Kronecker)</strong></em></p>
<p>Top-hat function: $H(x)=\begin{cases}a&amp;b&lt;=x&lt;=c\0&amp;else \end{cases}$</p>
<p>Image gratitude:$\nabla I_x(x,y)=I(x+1,y)-I(x-1,y),\nabla I_y(x,y)=I(x,y+1)-I(x,y-1)$</p>
<p><em><strong>Lemmas</strong></em></p>
<ol>
<li>$R(P(I))=P(R(I)), S(P(I))=P(S(I))$</li>
<li>$P(L\bigotimes k)=P(L)\bigotimes P(k)$</li>
</ol>
<p><em><strong>Invesigate P(L)</strong></em></p>
<p>The phase-only image can reveal a lot information about the texture and profile of a sharp image.</p>
<p>![image-20191126175240664](/Users/apple/Library/Application Support/typora-user-images/image-20191126175240664.png)</p>
<p><em><strong>Investigate P(k)</strong></em></p>
<p>First, assume the blur kernel is linear. Since $P$ has rotation and shift covariance (Lemma 1), we can assume that P is axis-aligned, so it can be seperated as follows:</p>
<p>$\mathbf k(x, y)=\delta(y)H(x)$</p>
<p>Extract phase-only image, we got:</p>
<p>$P(\mathbf k)(x, y)=\delta(y)P(H)(x)$</p>
<p>P(H) has two principle peaks. Note that $P(B)=P(L\bigotimes \mathbf k)=P(L)\bigotimes P(\mathbf k)$. Since $P(\mathbf k)$ has the shape like above, convolving $P(L)$ with $P(\mathbf k)$ <em><strong>(maybe firstly normalized)</strong></em> is equal to copying the edges in $P(L)$ twice, and the two copies correspond to the end and start point of blur kernel $\mathbf k$ seperately. Thus, they can estimate $\mathbf k$ from $P(B)$.</p>
<p>![image-20191126175633289](/Users/apple/Library/Application Support/typora-user-images/image-20191126175633289.png)</p>
<p><em><strong>Estimate k and L</strong></em></p>
<p>Since $P(B)$ can be seen as copyign the edge in $P(L)$ twice, and the two copy correspond to the end and start point of blur kernel $\mathbf k$ seperately, it may be able to use autocorrelation of $P(B)$ to estimate $P(\mathbf k)$.</p>
<p>However, $P(B)$’s self-correlation is always $\delta$ function, thus we can’t get useful information from it. This paper proposed that $|P(B)|$ instead of $P(B)$ has meaningful autocorrelation that can indicate $P(\mathbf k)$.</p>
<p>The autocorrelation of $|P(B)|$ is also a 2-d image, which is central symmetric. As showed below, the autocorrelation has 2 symmetric peak points, which indicates the orientation and length of blur kernel $\mathbf k$. After getting $\mathbf k$, they estimate the sharp image $L$ by solving an optimization problem:</p>
<p>$L = argmin_L ||\mathbf k \bigotimes L-B||^2+\mu_2h(\nabla L)$</p>
<p>$h(\nabla L)$ is an regularizaion term aims at preventing $L$ from having too much noise and too sharp edge:</p>
<p>$h(\nabla L)=\sum_{x,y} min(||\nabla L(x,y)/\epsilon||^2,1)$</p>
<p>![image-20191125162456978](/Users/apple/Library/Application Support/typora-user-images/image-20191125162456978.png)</p>
<p>If the blur is linear, then it’s easy to estimate $\mathbf k$ from $A(|P(B)|)$, since it only has two peak points. However, when the blur is non-linear, there will be many peak points in $A(|P(B)|)$, like showed above. Thus, this paper propose to firstly estimate a coarse blue kernel, then refine it in an iterative way. The optimization goal is:</p>
<p>$L = argmin_L ||\mathbf k \bigotimes L-B||^2+\mu_1||\mathbf k||^2+\mu_2h(\nabla L)$</p>
<p><em><strong>The solution of this optimization problem involves half quadratic splitting and solving in fourier domain, which is out of my knowledge.</strong></em> </p>
<p><em><strong>Extend to non-uniform blur</strong></em></p>
<p>For extension to non-uniform blur, the author proposed to divide the whole image into small patches, and assume that motion inside one patch is uniform. Thus, we can use method described above to deblur each patch seperately, then attached them together. </p>
<p><strong><code>Blind Image Deblurring With Local Maximum Gradient Prior</code></strong></p>
<p>Chen, Liang, et al. “Blind Image Deblurring With Local Maximum Gradient Prior.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2019.</p>
<p><strong>Abstract</strong></p>
<p>This paper proposed a new image prior named LMG (local maximum gradient), which is based on the observation that the maximum value of gradient will diminish after blurring in local patch.</p>
<p><strong>Method</strong></p>
<p><em><strong>Notations</strong></em></p>
<p>$c$: color channel of image, $c \in &lt;!–swig￼4–&gt;$</p>
<p>$x$: coordinates of a pixel in image, $x=(row, col)$</p>
<p>$P(x)$: a local patch centered at $x$</p>
<p><em><strong>LMG prior</strong></em></p>
<p>$LMG(I)(x)=max_{c\in&lt;!–swig￼5–&gt;}(max_{y\in P(x)} |\nabla I^c(y)|)$</p>
<p><em><strong>Proporties</strong></em></p>
<ol>
<li>$0&lt;=LMG(I)(x)&lt;=2$ <em><strong>(because the value of pixels are normalized.)</strong></em></li>
<li>Given $B=I\bigotimes \mathbf k$, we have $LMG(B)(x)&lt;=LMG(I)(x)$ hold for all x</li>
</ol>
<p><em><strong>Regularization term based on LMG</strong></em></p>
<p>Since blurring process tend to reduce the value of LMG, our goal is to make the LMG of latent image to get larger (close to 2). Thus this paper uses $||2-LMG(I)||_1$ as regularization term.</p>
<p><em><strong>Final energy function</strong></em></p>
<p>$\mathop{min} \limits_{I,\mathbf k} ||B-I\bigotimes \mathbf k||^2+\beta ||2-LMG(I)||_1+\gamma ||\nabla I||_0+\tau ||\mathbf k||^2$</p>
<p>$||B-I\bigotimes \mathbf k||^2$: fidelity term, ensure the similarity between observed blur image B and the deconvolution result;</p>
<p>$||2-LMG(I)||_1$: LMG prior mentioned above;</p>
<p>$||\nabla I||_0$: the $L_0$ norm of gradient, can be seen as # of non-zero gradients, used for ensuring that only the salient edges are retained, and the tiny edges are removed. It’s based on the assumption that natural image should have sparse gradient;</p>
<p>$||\mathbf k||^2$: used to ensure the blur kernel is smooth.</p>
<p><em><strong>Algorithm</strong></em></p>
<p>Iteratively optimize $I$ and $\mathbf k$ <em><strong>(why?)</strong></em> by solving these 2 problems:</p>
<p>$\begin{cases} \mathop{min} \limits_{I} ||B-I\bigotimes \mathbf k||^2+\beta ||2-LMG(I)||_1+\gamma ||\nabla I||<em>0,\\mathop{min} \limits</em>{\mathbf k} ||B-I\bigotimes \mathbf k||^2+\tau ||\mathbf k||^2.\end{cases}$</p>
<h3 id="Blind-single-image-deblurring-Dl-based"><a href="#Blind-single-image-deblurring-Dl-based" class="headerlink" title="Blind single image deblurring (Dl-based)"></a>Blind single image deblurring (Dl-based)</h3><p><strong><code>Unsupervised Domain-Specific Deblurring via Disentangled Representations</code></strong></p>
<p><strong><code>Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring</code></strong></p>
<p>Nah, Seungjun, Tae Hyun Kim, and Kyoung Mu Lee. “Deep multi-scale convolutional neural network for dynamic scene deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2017.</p>
<p><strong>Network architecture</strong></p>
<p>![image-20191204122343572](/Users/apple/Library/Application Support/typora-user-images/image-20191204122343572.png)</p>
<p><strong>Loss function</strong></p>
<p>$L=L_{content}+\lambda L_{adv},$</p>
<p>$L_{content}=\frac{1}{2K}\sum \limits_{k=1}\limits^K\frac{1}{c_kh_kw_k}||G_k(B)-I_k||^2$, where k represent an image scale.</p>
<p>$L_{adv}=\mathop{E} \limits_{I\sim p_{sharp}}[logD(I)]+\mathop{E} \limits_{B\sim p_{blur}}[log(1-D(G(B)))]$</p>
<p><strong><code>Scale-recurrent network for deep image deblurring</code></strong></p>
<p>Tao, Xin, et al. “Scale-recurrent network for deep image deblurring.” <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>. 2018.</p>
<p><strong>Network architecture</strong></p>
<p><em>Mention: the same parameters are used for all scales.</em></p>
<p>![image-20191204124337711](/Users/apple/Library/Application Support/typora-user-images/image-20191204124337711.png)</p>
<p><strong>Loss function</strong></p>
<p>Only content loss</p>
<h3 id="Non-blind-single-image-deblurring"><a href="#Non-blind-single-image-deblurring" class="headerlink" title="Non-blind single image deblurring"></a>Non-blind single image deblurring</h3><h3 id="Multi-image-video-deblurring"><a href="#Multi-image-video-deblurring" class="headerlink" title="Multi-image/video deblurring"></a>Multi-image/video deblurring</h3><h2 id="Out-of-focus-deblur"><a href="#Out-of-focus-deblur" class="headerlink" title="Out-of-focus deblur"></a>Out-of-focus deblur</h2><h2 id="Denoising"><a href="#Denoising" class="headerlink" title="Denoising"></a>Denoising</h2><p><strong><code>Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections</code></strong></p>
<p>Mao, Xiaojiao, Chunhua Shen, and Yu-Bin Yang. “Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections.” <em>Advances in neural information processing systems</em>. 2016.</p>
<p><strong>Abstract</strong></p>
<p>This paper proposed to use U-net with residual conv blocks and skip connections for image restoration. They did experiments on 2 restoration tasks: denoising and super-resolution, to confirm the efficiency of their method.</p>
<h2 id="Super-resolution"><a href="#Super-resolution" class="headerlink" title="Super resolution"></a>Super resolution</h2>
  </div>
  <div>
  
  <div class="post-note note-warning copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://example.com/about">theme-kaze</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://example.com/2022/02/20/image_restoration/">http://example.com/2022/02/20/image_restoration/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/2022/02/20/image_classification/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">Prev</div>
        
        <div class="nav-title">图像分类算法综述 </div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/2022/02/20/machine_learning/" class="nav-link">
      <div>
        <div class="nav-label">Next</div>
        
        <div class="nav-title">机器学习 </div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F"><span class="toc-text">图像复原</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motion-deblur"><span class="toc-text">Motion deblur</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Blind-single-image-deblurring-Optimization-based"><span class="toc-text">Blind single image deblurring (Optimization-based)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blind-single-image-deblurring-Dl-based"><span class="toc-text">Blind single image deblurring (Dl-based)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-blind-single-image-deblurring"><span class="toc-text">Non-blind single image deblurring</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-image-video-deblurring"><span class="toc-text">Multi-image&#x2F;video deblurring</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Out-of-focus-deblur"><span class="toc-text">Out-of-focus deblur</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Denoising"><span class="toc-text">Denoising</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Super-resolution"><span class="toc-text">Super resolution</span></a></li></ol></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/img/Kaze.png" class="author-img">

<p class="author-name">theme-kaze</p>
<p class="author-description">designed by theme-kaze</p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>23</span>
    <span>Posts</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>0</span>
    <span>Categories</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>6</span>
    <span>Tags</span>
  </a>
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F"><span class="toc-text">图像复原</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motion-deblur"><span class="toc-text">Motion deblur</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Blind-single-image-deblurring-Optimization-based"><span class="toc-text">Blind single image deblurring (Optimization-based)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blind-single-image-deblurring-Dl-based"><span class="toc-text">Blind single image deblurring (Dl-based)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-blind-single-image-deblurring"><span class="toc-text">Non-blind single image deblurring</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-image-video-deblurring"><span class="toc-text">Multi-image&#x2F;video deblurring</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Out-of-focus-deblur"><span class="toc-text">Out-of-focus deblur</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Denoising"><span class="toc-text">Denoising</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Super-resolution"><span class="toc-text">Super resolution</span></a></li></ol></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>Categories</div>
  <div class="categories-list">
    
  </div>
</div>
  </article>
  
  <article class="card card-content">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>hot tags</div>
  <div class="tags-list">
    
    <a href="\tags\Programming" title="Programming"><div class="tags-list-item">Programming</div></a>
    
    <a href="\tags\Computer vision" title="Computer vision"><div class="tags-list-item">Computer vision</div></a>
    
    <a href="\tags\Machine learning" title="Machine learning"><div class="tags-list-item">Machine learning</div></a>
    
    <a href="\tags\机器学习" title="机器学习"><div class="tags-list-item">机器学习</div></a>
    
    <a href="\tags\Deep learning" title="Deep learning"><div class="tags-list-item">Deep learning</div></a>
    
    <a href="\tags\Deep learning, Programming" title="Deep learning, Programming"><div class="tags-list-item">Deep learning, Programming</div></a>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">
  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F"><span class="toc-text">图像复原</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motion-deblur"><span class="toc-text">Motion deblur</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Blind-single-image-deblurring-Optimization-based"><span class="toc-text">Blind single image deblurring (Optimization-based)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blind-single-image-deblurring-Dl-based"><span class="toc-text">Blind single image deblurring (Dl-based)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-blind-single-image-deblurring"><span class="toc-text">Non-blind single image deblurring</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-image-video-deblurring"><span class="toc-text">Multi-image&#x2F;video deblurring</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Out-of-focus-deblur"><span class="toc-text">Out-of-focus deblur</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Denoising"><span class="toc-text">Denoising</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Super-resolution"><span class="toc-text">Super resolution</span></a></li></ol></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>Recent Posts</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2022-02-20</div>
        <a href="/2022/02/20/image_processing/"><div class="recent-posts-item-content">数字图像处理基础</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2022-02-20</div>
        <a href="/2022/02/20/python_manual/"><div class="recent-posts-item-content">Python使用手册</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2022-02-20</div>
        <a href="/2022/02/20/pytorch_manual/"><div class="recent-posts-item-content">PyTorch使用手册</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2022-02-20</div>
        <a href="/2022/02/20/cnn/"><div class="recent-posts-item-content">卷积神经网络</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2022
        </span>
        <a href="/" class="footer-link">theme-kaze demo </a>
      </div>
    </div>

    
    <div class="footer-dsc">
      
      
      Powered by
      <a href="https://hexo.io/" class="footer-link" target="_blank" rel="nofollow noopener noreferrer">&nbsp;Hexo </a>
      
      
      <span>&nbsp;|&nbsp;</span>
      
      
      
      Theme -
      <a href="https://github.com/theme-kaze" class="footer-link" target="_blank"
        rel="nofollow noopener noreferrer">&nbsp;Kaze</a>
      
    </div>
    
    
    
    
</footer>
  <a role="button" id="scrollbutton" class="basebutton" >
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget">
  <i class="iconfont icon-weather button-icon"></i>
</a>

  
  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.setAttribute('style', 'width: 100%; display: flex; justify-content: center;');
      img[i].parentElement.insertBefore(wrapper, img[i]);
      wrapper.appendChild(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
</body>

</html>